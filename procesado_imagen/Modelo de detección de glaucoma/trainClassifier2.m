function [trainedClassifier, validationAccuracy] = trainClassifier2(trainingData)
% [trainedClassifier, validationAccuracy] = trainClassifier(trainingData)
% Returns a trained classifier and its accuracy. This code recreates the
% classification model trained in Classification Learner app. Use the
% generated code to automate training the same model with new data, or to
% learn how to programmatically train models.
%
%  Input:
%      trainingData: A table containing the same predictor and response
%       columns as those imported into the app.
%
%
%  Output:
%      trainedClassifier: A struct containing the trained classifier. The
%       struct contains various fields with information about the trained
%       classifier.
%
%      trainedClassifier.predictFcn: A function to make predictions on new
%       data.
%
%      validationAccuracy: A double representing the validation accuracy as
%       a percentage. In the app, the Models pane displays the validation
%       accuracy for each model.
%
% Use the code to train the model with new data. To retrain your
% classifier, call the function from the command line with your original
% data or new data as the input argument trainingData.
%
% For example, to retrain a classifier trained with the original data set
% T, enter:
%   [trainedClassifier, validationAccuracy] = trainClassifier(T)
%
% To make predictions with the returned 'trainedClassifier' on new data T2,
% use
%   [yfit,scores] = trainedClassifier.predictFcn(T2)
%
% T2 must be a table containing at least the same predictor columns as used
% during training. For details, enter:
%   trainedClassifier.HowToPredict

% Auto-generated by MATLAB on 10-Jun-2024 16:10:29

rng(4);

% Extract predictors and response
% This code processes the data into the right shape for training the
% model.
inputTable = trainingData;
predictorNames = {'Area', 'Entropia', 'Ratio', 'Media', 'Energia_cD', 'Media_cD'};
predictors = inputTable(:, predictorNames);
response = inputTable.Glaucoma;
isCategoricalPredictor = [false, false, false, false, false, false];
classNames = [0; 1];

% Train a classifier
% This code specifies all the classifier options and trains the classifier.
classificationKernel = fitckernel(...
    predictors, ...
    response, ...
    'Learner', 'logistic', ...
    'NumExpansionDimensions', 'auto', ...
    'Lambda', 'auto', ...
    'KernelScale', 'auto', ...
    'Standardize', true, ...
    'IterationLimit', 1000, ...
    'ClassNames', classNames);

% Create the result struct with predict function
predictorExtractionFcn = @(t) t(:, predictorNames);
kernelPredictFcn = @(x) predict(classificationKernel, x);
trainedClassifier.predictFcn = @(x) kernelPredictFcn(predictorExtractionFcn(x));

% Add additional fields to the result struct
trainedClassifier.RequiredVariables = {'Area', 'Entropia', 'Ratio', 'Media', 'Energia_cD', 'Media_cD'};
trainedClassifier.ClassificationKernel = classificationKernel;
trainedClassifier.About = 'This struct is a trained model exported from Classification Learner R2024a.';
trainedClassifier.HowToPredict = sprintf('To make predictions on a new table, T, use: \n  [yfit,scores] = c.predictFcn(T) \nreplacing ''c'' with the name of the variable that is this struct, e.g. ''trainedModel''. \n \nThe table, T, must contain the variables returned by: \n  c.RequiredVariables \nVariable formats (e.g. matrix/vector, datatype) must match the original training data. \nAdditional variables are ignored. \n \nFor more information, see <a href="matlab:helpview(fullfile(docroot, ''stats'', ''stats.map''), ''appclassification_exportmodeltoworkspace'')">How to predict using an exported model</a>.');

% Extract predictors and response
% This code processes the data into the right shape for training the
% model.
inputTable = trainingData;
predictorNames = {'Area', 'Entropia', 'Ratio', 'Media', 'Energia_cD', 'Media_cD'};
predictors = inputTable(:, predictorNames);
response = inputTable.Glaucoma;
isCategoricalPredictor = [false, false, false, false, false, false];
classNames = [0; 1];

% Perform cross-validation
KFolds = 10;
cvp = cvpartition(response, 'KFold', KFolds);
% Initialize the predictions to the proper sizes
validationPredictions = response;
numObservations = size(predictors, 1);
numClasses = 2;
validationScores = NaN(numObservations, numClasses);
for fold = 1:KFolds
    trainingPredictors = predictors(cvp.training(fold), :);
    trainingResponse = response(cvp.training(fold), :);
    foldIsCategoricalPredictor = isCategoricalPredictor;

    % Train a classifier
    % This code specifies all the classifier options and trains the classifier.
    classificationKernel = fitckernel(...
        trainingPredictors, ...
        trainingResponse, ...
        'Learner', 'logistic', ...
        'NumExpansionDimensions', 'auto', ...
        'Lambda', 'auto', ...
        'KernelScale', 'auto', ...
        'Standardize', true, ...
        'IterationLimit', 1000, ...
        'ClassNames', classNames);

    % Create the result struct with predict function
    kernelPredictFcn = @(x) predict(classificationKernel, x);
    validationPredictFcn = @(x) kernelPredictFcn(x);

    % Add additional fields to the result struct

    % Compute validation predictions
    validationPredictors = predictors(cvp.test(fold), :);
    [foldPredictions, foldScores] = validationPredictFcn(validationPredictors);

    % Store predictions in the original order
    validationPredictions(cvp.test(fold), :) = foldPredictions;
    validationScores(cvp.test(fold), :) = foldScores;
end

% Compute validation accuracy
correctPredictions = (validationPredictions == response);
isMissing = isnan(response);
correctPredictions = correctPredictions(~isMissing);
validationAccuracy = sum(correctPredictions)/length(correctPredictions);
